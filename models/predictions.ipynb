{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from  datetime import datetime, timedelta\n",
    "\n",
    "data_folder = '..//data//'\n",
    "submission_folder = '..//submissions//'\n",
    "features_folder = '..//features//'\n",
    "models_path = '..//models//' \n",
    "\n",
    "d_parser = lambda x: pd.datetime.strptime(x,'%Y-%m-%d')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_name = 'model_feat_2_1100d.pkl'\n",
    "lgb = joblib.load(os.path.join(models_path,model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(features_folder,'X_train_2.csv'))\n",
    "#y_train = pd.read_csv(os.path.join(features_folder,'y_train_2.csv'))\n",
    "X_valid = pd.read_csv(os.path.join(features_folder,'X_valid_2.csv'))\n",
    "#y_valid = pd.read_csv(os.path.join(features_folder,'y_valid_2.csv'))\n",
    "#X_test = pd.read_csv(os.path.join(features_folder,'X_test_2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_cols = X_valid.columns[X_valid.columns.isin(X_train.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as DT\n",
    "\n",
    "preds_valid = lgb.predict(X_valid[X_valid_cols])\n",
    "#preds_eval =  lgb.predict(X_valid[X_valid_cols])\n",
    "\n",
    "df_submission_valid= X_valid[['id','d']]\n",
    "df_submission_valid['target'] = preds_valid.clip(0,preds_valid.max())\n",
    "\n",
    "col_append = ['F'+str(i) for i in range(1,29)]\n",
    "\n",
    "#valid set\n",
    "submission_pivot_valid = df_submission_valid.pivot_table('target', ['id'], 'd')\n",
    "submission_pivot_valid.columns = col_append\n",
    "submission_pivot_valid = submission_pivot_valid.reset_index()\n",
    "\n",
    "submission_pivot_eval = submission_pivot_valid.copy()\n",
    "submission_pivot_eval['id'] = submission_pivot_eval['id'].str.replace('validation$', 'evaluation')\n",
    "\n",
    "#Concatenating\n",
    "df_submission = pd.concat([submission_pivot_valid, submission_pivot_eval], axis=0)\n",
    "df_sample_sub = pd.read_csv(os.path.join(data_folder,'sample_submission.csv'))\n",
    "df_submission = df_sample_sub[['id']].merge(df_submission, how='inner', on='id')\n",
    "\n",
    "\n",
    "model_name = 'lgb_feat_2_1100d_duplicate'\n",
    "file_name =  'sub_' + model_name\n",
    "save_path = file_name + '_' + str(DT.date.today()) + '.csv'\n",
    "df_submission.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for feature three model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_feat_3_370d.lgb'\n",
    "lgb = joblib.load(os.path.join(models_path,model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(features_folder,'X_train_3.csv'))\n",
    "y_train = pd.read_csv(os.path.join(features_folder,'y_train_3.csv'))\n",
    "X_valid = pd.read_csv(os.path.join(features_folder,'X_valid_3.csv'))\n",
    "y_valid = pd.read_csv(os.path.join(features_folder,'y_valid_3.csv'))\n",
    "X_test = pd.read_csv(os.path.join(features_folder,'X_test_3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_cols = X_valid.columns[X_valid.columns.isin(X_train.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as DT\n",
    "\n",
    "preds_valid = lgb.predict(X_valid[X_valid_cols])\n",
    "preds_eval =  lgb.predict(X_test[X_valid_cols])\n",
    "df_submission_valid= X_valid[['id','d']]\n",
    "df_submission_valid['target'] = preds_valid.clip(0,preds_valid.max())\n",
    "df_submission_eval = X_test[['id','d']]\n",
    "df_submission_eval['target'] = preds_eval.clip(0,preds_eval.max())\n",
    "col_append = ['F'+str(i) for i in range(1,29)]\n",
    "#valid set\n",
    "submission_pivot_valid = df_submission_valid.pivot_table('target', ['id'], 'd')\n",
    "submission_pivot_valid.columns = col_append\n",
    "submission_pivot_valid = submission_pivot_valid.reset_index()\n",
    "\n",
    "#eval set\n",
    "submission_pivot_eval = df_submission_eval.pivot_table('target', ['id'], 'd')\n",
    "submission_pivot_eval.columns = col_append\n",
    "submission_pivot_eval = submission_pivot_eval.reset_index()\n",
    "\n",
    "#Concatenating\n",
    "df_submission = pd.concat([submission_pivot_valid, submission_pivot_eval], axis=0)\n",
    "df_sample_sub = pd.read_csv(os.path.join(data_folder,'sample_submission.csv'))\n",
    "df_submission = df_sample_sub[['id']].merge(df_submission, how='inner', on='id')\n",
    "\n",
    "file_name =  'sub_' + model_name\n",
    "save_path = file_name + '_' + str(DT.date.today()) + '.csv'\n",
    "df_submission.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Prediction by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src/')\n",
    "import prepare2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook2 = prepare2.M5AccuracyCook2(features_folder,data_folder,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "1941 1\n",
      "1941 1\n",
      "1941 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941 1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.53s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941 1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:32<00:00, 90.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941 1941\n",
      "1941 1941\n"
     ]
    }
   ],
   "source": [
    "df_test = cook2.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1/len(alphas)]*len(alphas)\n",
    "sub = 0.\n",
    "\n",
    "for icount, (alpha,weight) in enumerate(zip(alphas,weights)):\n",
    "    \n",
    "    cols = [f'F{i}' for i in range(1,29)]\n",
    "    \n",
    "    for tdelta in range(0,28):\n",
    "        dftst_by_day = df_test[df_test==]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
